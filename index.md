---
layout: page
name: index
title: Personal Website
description: >
  Personal Website of Ling-Qi, PhD Candidate in Computational Neuroscience at Penn.
hide_description: true
---

<style type="text/css">
	.page-title {
		position: absolute;
		width: 1px;
  		height: 1px;
  		margin: -1px;
  		border: 0;
  		padding: 0;
  		clip: rect(0 0 0 0);
  		overflow: hidden;
	}
</style>

<h2 class="h1" style="color: rgb(0,0,0)" id="about">About Me </h2>

Hi there! Welcome to my website! My name is Jeesung Ahn, I am a 4th-year Ph.D. candidate in the [Department of Psychology](https://psychology.sas.upenn.edu) at the University of Pennsylvania, studying how to effectively persuade people to engage in healthier lifestyles. I am working with [Emily Falk](https://www.asc.upenn.edu/people/faculty/emily-falk-phd) at the [Communication Neuroscience Lab](http://cni.upenn.edu/).

My current research mainly revolves around two topics: 
• using the brain-as-predictor approach to evaluate the effectiveness of persuasive messages in promoting health behaviors (e.g., physical activity)
• understanding how brain networks and social networks are associated with individual differences in healthy lifestyles and mental well-being (e.g., loneliness).

Over the course of 7+ years leading psychology and neuroimaging research projects, I have primarily worked with human behavioral and brain data in the experimental psychology and social neuroscience domains. My research methods are multi-disciplinary and include experimental design (A/B testing), survey/behavioral/neuroimaging data collection, meta-analysis, content analysis, descriptive/parametric/multivariate statistics, general linear modeling, multilevel modeling, time-series analysis, computational network analysis, and machine-learning classification.

I am passionate about communicating and translating scientific insights into practical and actionable outcomes in complex decision-making scenarios. To that end, I have been actively involved with various social group activities where I can leverage my research skills to make real-world impacts on matters that I care about (e.g., consulting for a healthcare company, analyzing/visualizing data for an educational diversity and equity initiative, analyzing/visualizing climate-related data to inform climate activists).

---
<h2 class="h1" style="color: rgb(0,0,0)" id="research">Research </h2>
<h3 class="h2">Selected Projects</h3>

**BEHAVIORAL AND NEURAL EFFICIENT CODING OF SPEED**  
*[\[JNeurosci, 2022\]](https://www.jneurosci.org/content/42/14/2951)  [\[V-VSS 2021 Poster\]](https://www.youtube.com/watch?v=W5DH4h2dH8Y)  [\[GitHub\]](https://github.com/lingqiz/Speed_Prior_2021)* <br>

<div class="row">
  <div class="column">
  <img class="proj-image" src="/assets/img/speedPrior.png" style="height: 100%; width: 100%; object-fit: contain">
  </div>

  <div class="column" markdown="1">
  We built an efficient encoding, Bayeisan decoding model for human speed perception in a psychophysical experiment. The model makes specific perdictions regarding the neural encoding characteristics of retinal speed, which we validated by analyzing electrophysiology recording of MT neurons.
  </div>
</div>

<br>
**BAYESIAN IMAGE RECONSTRUCTION FROM CONE MOSAIC SIGNAL**  
*[\[eLife, 2022\]](https://elifesciences.org/articles/71132)  [\[V-VSS 2020 Talk\]](https://youtu.be/d5qI0FNCAv4)  [\[GitHub\]](https://github.com/isetbio/ISETImagePipeline)* <br>

<div class="row">
  <div class="column">
  <img class="proj-image" src="/assets/img/imageRecon.png" style="height: 100%; width: 100%; object-fit: contain">
  </div>

  <div class="column" markdown="1">
  We built a Bayesian image reconstruction algorithm from cone excitations based on an accurate model of human early vision, in order to understand information loss at the very first step of visual processing. Our model enables quantitative analysis of retinal mosaic design, visualization, and the more "traditional" ideal observer type of analysis.
  </div>
</div>

<br>
**VISUAL ORIENTATION ENCODING IN INDIVIDUALS WITH AUTISM**  
*[\[PLOS Biology, 2021\]](https://doi.org/10.1371/journal.pbio.3001215)  [\[Primer\]](https://doi.org/10.1371/journal.pbio.3001293)  [\[Data+Code\]](https://github.com/lingqiz/ASD_Encoding_2020)* <br>

<div class="row">
  <div class="column">
  <img class="proj-image" src="/assets/img/encodingASD.png" style="height: 100%; width: 100%; object-fit: contain">
  </div>

  <div class="column" markdown="1">
  We compared the accuracy of visual orientation encoding between neurotypical and ASD groups using an information theoretic measure. We found that the ASD group starts with an overall lower encoding capacity, which does not improve when presented with performance feedback. They are also less adaptive to the stimulus statistics in contrast to the neurotypical subjects.
  </div>
</div>

<br>
**PSYCHOPHYSICS WITH DEEP NEURAL NETWORKS**  
*[\[CCN, 2019\]](https://ccneuro.org/2019/proceedings/0000585.pdf)* <br>

<div class="row">
  <div class="column">
  <img class="proj-image" src="/assets/img/ccn2019.png" style="height: 100%; width: 100%; object-fit: contain">
  </div>

  <div class="column" markdown="1">
  We showed that pretrained neural networks, like humans, have internal representations that overrepresent frequent variable values at the expense of certainty for less common values. Furthermore, we demonstrated that optimized readouts of local visual orientation from these networks’ internal representations show similar orientation biases and geometric illusions, just as human subjects.
  </div>
</div>

<br>
**COURSE PROJECT (CSE 167x/168x, COMPUTER GRAPHICS)**  
*[\[Simple Python Ray Tracer\]](https://github.com/lingqiz/CSE-167x-RayTracer)  [\[Path Tracer with OptiX\]](https://github.com/lingqiz/CSE-168x-OptiX)* <br>

<div class="row">
  <div class="column">
  <img class="proj-image" src="/assets/img/cse167.png" style="height: 100%; width: 100%; object-fit: contain">
  </div>

  <div class="column" markdown="1">
  Basics of physically based rendering: Implementation of basic Whitted Ray-Tracing with Python, and a Monte Carlo Path Tracer with NVIDIA OptiX.
  </div>
</div>

<br>
**COURSE PROJECT (STAT 927, BAYESIAN STATISTICS)**  
*[\[Data+Code\]](https://github.com/zlqzcc/DoublePassBayesian)* <br>

<div class="row">
  <div class="column">
  <img class="proj-image" src="/assets/img/bayesian.png" style="height: 100%; width: 100%; object-fit: contain">
  </div>

  <div class="column" markdown="1">
  Implementation of a hierarchical Bayesian model for parameter estimation of a non-trivial psychophysical experiment (inferring the partitioning of internal vs. external noise in depth perception). Posterior computation with Gibbs sampler nested with Metropolis-Hastings algorithm.
  </div>
</div>

---
<h2 class="h1" style="color: rgb(0,0,0)" id="publications">Publications </h2>

* AS Benjamin, **LQ Zhang**, C Qiu, AA Stocker, and KP Kording.
[Efficient neural codes naturally emerge through gradient descent learning](https://www.biorxiv.org/content/10.1101/2022.05.11.491548v1). Nature Communications (in press), 2022.

* **LQ Zhang** and AA Stocker.
[Prior expectations in visual speed perception predict encoding characteristics of neurons in area MT](https://www.jneurosci.org/content/42/14/2951). Journal of Neuroscience, 2022.

* **LQ Zhang**, NP Cottaris, and DH Brainard.
[An image reconstruction framework for characterizing initial visual encoding](https://elifesciences.org/articles/71132). eLife, 2022.

* JP Noel†, **LQ Zhang†**, AA Stocker, and DE Angelaki.
[Individuals with autism spectrum disorder have altered visual encoding capacity](https://doi.org/10.1371/journal.pbio.3001215). PLOS Biology, 2021.

* AS Benjamin†, C Qiu†, **LQ Zhang†**, KP Kording, and AA Stocker. [Shared visual illusions between humans and artificial neural networks](https://ccneuro.org/2019/proceedings/0000585.pdf). 2019 Conference on Cognitive Computational Neuroscience.

* MAK Peters†, **LQ Zhang†**, and L Shams. [The material-weight illusion is a Bayes-optimal percept under competing density priors](https://peerj.com/articles/5760/). PeerJ, 2018.

* Z Fang, **LQ Zhang**, and K Chen. [A behavior mining based hybrid recommender system](https://ieeexplore.ieee.org/abstract/document/7509785/). 2016 IEEE International Conference Big Data Analysis (ICBDA).

**(† deonotes co-first authorship)**

---
<h2 class="h1" style="color: rgb(0,0,0)" id="contact-me">Contact </h2>

425 S. University Ave  
Philadelphia, PA 19104  

<p class="home-element"><strong>lingqiz [at] sas [dot] upenn [dot] edu</strong></p>

<style type="text/css">
  .body-social > ul {
    display: inline-block;
    list-style-type: none;
    margin-bottom: 0;
    overflow: hidden;
    padding: 0;
  }

  .body-social > ul > li {
    float: left;

    /* padding-left: 5px; */
    padding-right: 10px;

    /* display: inline-block; */
  }

  .body-social > ul > li > a {
    display: inline;
    text-align: center;
    font-size: 0.95rem;
    font-weight: 600;
    /*width: 3rem;*/
    /*height: 4rem;*/
    padding: 4px;

    /* line-height: 3rem; */

    text-decoration: none;
    border-width: 1px;
    border-style: solid;
    border-radius: 5px;
    transition: background-color 250ms, color 250ms, text-decoration-color 250ms, border-color 250ms;

    /* border-bottom: none; */
  }

  .body-social > ul > li > a:not(.btn):not(.no-hover) {
    border-color: var(--accent-color);
  }

  .body-social > ul > li > a:hover {
    color: white;
    background-color: var(--accent-color);
    border-radius: 5px;
    padding: 4px;
    transition: background-color 250ms, color 250ms, text-decoration-color 250ms, border-color 250ms;
  }

  .row {
    display: flex;
  }

  .column {
    flex: 50%;
  }

  img.proj-image {
    display: block;
    margin-right: auto;
    padding-right: 20px;
  }
</style>
